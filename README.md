# Sports-Sales-Analytics-Dashboar

# ðŸ† Sports Sales Analytics Dashboard

## ðŸ” Project Overview

This project focuses on analyzing a **Sports Sales Dataset** through an end-to-end **ETL (Extract, Transform, Load)** and **data cleaning** pipeline, followed by the development of an interactive **business intelligence dashboard**. The goal is to extract meaningful insights from the sales data, clean and transform it into a structured format, and visualize key business metrics to support decision-making.

---

## ðŸ“Š Dataset Used

**Dataset Name:** Sports Sales Dataset  
**Description:** The dataset contains historical sales records for various sports-related products across different regions, retailers, and time periods. It includes details such as product information, units sold, sales amounts, sales methods, regions, cities, and more.

---

## ðŸ› ï¸ Project Objectives

1. **Data Extraction, Transformation & Loading (ETL):**
   - Extract raw data from the source.
   - Clean and preprocess the data (handling missing values, duplicates, inconsistencies).
   - Transform the data into a structured and analysis-ready format.
   - Load the cleaned data into a suitable format for analysis (e.g., CSV, DataFrame, or database).

2. **Data Visualization & Dashboard:**
   - Build an interactive **dashboard** to present key sales insights.
   - Visualize critical KPIs and trends using modern data visualization techniques.

---

## ðŸ“ˆ Key Visualizations & Features

The dashboard includes the following visual components:

### ðŸ“Œ KPI Summary (Cards)
- **Total Products**
- **Total Units Sold**
- **Total Sales Amount**

### ðŸ¥§ Distribution Visualizations
- **Sales Amount by Sales Method** â†’ *Pie Chart*
- **Total Sales by Region** â†’ *Donut Chart*

### ðŸ“Š Comparative Visualizations
- **Total Sales by Retailer** â†’ *Bar Chart*
- **Total Sales by Product** â†’ *Bar Chart*
- **Top 10 Cities by Sales Amount** â†’ *Bar Chart*
- **Total Units Sold by States** â†’ *Stacked Column Chart*

### ðŸ”½ Interactive Filters
- **Year Filter** â€“ Filter data by specific year(s)
- **Region Filter** â€“ Filter data by selected region(s)

These filters allow dynamic exploration of the dataset based on user-selected criteria.

---

## ðŸ—‚ï¸ Project Structure

```
sports-sales-analytics/
â”‚
â”œâ”€â”€ data/                      # Raw and processed datasets
â”‚   â”œâ”€â”€ raw_sales_data.csv     # Original dataset
â”‚   â””â”€â”€ cleaned_sales_data.csv # ETL processed data
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter Notebooks (if used)
â”‚   â””â”€â”€ ETL_and_Analysis.ipynb # ETL & analysis steps
â”‚
â”œâ”€â”€ src/                       # Source code (if applicable)
â”‚   â””â”€â”€ etl_script.py          # Script for ETL process
â”‚
â”œâ”€â”€ dashboard/                 # Dashboard files (if using tools like Streamlit, Power BI, etc.)
â”‚   â””â”€â”€ app.py / dashboard.html
â”‚
â”œâ”€â”€ README.md                  # This file
â””â”€â”€ requirements.txt           # Python dependencies (if any)
```

> âš ï¸ *Note: File structure may vary depending on technologies used (e.g., Python, Power BI, Tableau, etc.). Adjust paths accordingly.*

---

## ðŸ§° Technologies Used

- **Programming Language:** Python (or other, specify if different)
- **Data Processing:** Pandas, NumPy
- **Data Cleaning:** Custom Python scripts / Pandas
- **Visualization:** 
  - Matplotlib / Seaborn / Plotly (for static or interactive charts)
  - **OR**
  - **Power BI / Tableau / Streamlit** (if used for dashboard)
- **ETL Process:** Custom ETL Scripts
- **Tools (if applicable):** Jupyter Notebook, Excel (for initial inspection), Git

---

## ðŸš€ How to Run the Project

> Instructions will vary depending on how you've built the project (e.g., Python scripts, notebooks, Streamlit app, etc.). Below is a **generic guide** â€” update it based on your actual setup.

### Option 1: If using Python Scripts / Notebooks
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/sports-sales-analytics.git
   cd sports-sales-analytics
   ```
2. Install required packages (if `requirements.txt` exists):
   ```bash
   pip install -r requirements.txt
   ```
3. Run the ETL script:
   ```bash
   python src/etl_script.py
   ```
4. Open the notebook or dashboard app:
   ```bash
   jupyter notebook notebooks/ETL_and_Analysis.ipynb
   ```
   **OR**
   ```bash
   streamlit run dashboard/app.py
   ```

### Option 2: If using BI Tools 
- Open the `.pbix` file in Power BI.
- Connect to the `cleaned_sales_data.csv` from the `/data` folder.
- Interact with the dashboard using the provided filters.

---

## ðŸ“‹ ETL & Data Cleaning Process (Summary)

- **Extract:** Loaded the raw sales dataset.
- **Transform:**
  - Handled missing or null values.
  - Standardized categorical data (e.g., regions, sales methods).
  - Converted data types (e.g., dates, numeric fields).
  - Aggregated data where necessary (e.g., total sales, units).
- **Load:** Saved the cleaned dataset as `cleaned_sales_data.csv` for analysis and visualization.

---

## ðŸ“Š Insights Derived

- Identified top-performing **products**, **regions**, and **retailers**.
- Recognized high-sales **cities** and **states**.
- Analyzed the impact of **sales methods** on total revenue.
- Gained a **year-wise** and **region-wise** view of sales performance.



## ðŸ™Œ Contributors

- **Nishit Yadav** â€“ Data Analyst / Developer  
  https://github.com/yadavnishit

> *Feel free to add other team members or contributors here.*

---

## ðŸ“ž Contact

For questions or feedback, please contact:  
**Email:** nishit7902@gmail.com  
**GitHub:** https://github.com/yadavnishit

---

âœ… **Thank you for visiting the repository. Feel free to explore, contribute, or use the dashboard for your own analysis.**

---

> ðŸ”§ **Tip:** Update all placeholders like `your-username`, file paths, technologies, and names according to your actual project setup before pushing to GitHub.

Would you like me to generate a `requirements.txt` template or help with structuring the actual code folders as well?
